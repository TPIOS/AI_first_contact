#### 问题描述：

给予一个train训练集，带有每个单词和其所对应的词性，对于一个新的test，判断该词的词性

#### 目前研究成果：

 https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art) 

POS Tagging Accuracies • Rough accuracies: 

• Baseline: most freq tag: ~90% 

• Trigram HMM: ~95% 

• Maxent P(t|w): 93.7% 

• MEMM tagger: 96.9% 

• Bidirectional MEMM: 97.2% 

• Upper bound: ~98% (human agreement) 

#### 个人理解：

简单来讲就是$P(Tag|Word)$，也就是在给予该word的情况下，它所有可能的tag的概率是多少，然后从中选取最高的tag

$argmax_{Tag}(P(Tag|Word))$

单纯计算的话，$P(Tag|Word)=\frac{P(Tag, Word)}{P(Word)}$，其实也就是在问$P(Tag,Word)$。可以有进一步的转化$P(Tag,Word)=P(Word|Tag)*P(Tag)$

这样转换是为了HMM做准备，因为直接只通过一个单词去判断其词性，显然会丢失很多句子层面上的信息，这个单词或者这个单词词性的前面是谁，后面是谁，前面的前面是谁，后面的后面是谁，等等，都有可能跟这个单词的词性有密切联系，那么显然我们需要通过训练来得到有关单词词性前后的信息。

HMM模型告诉我们，假如说对于一个词，已知这个词前一个词的词性，那么计算这个词的词性，可以是$P(这个词词性|上一个词词性)*P(这个单词|这个词词性)$

#### 最大困难：

通过训练集得出对于训练集的$P(这个词词性|上一个词词性)*P(这个单词|这个词词性)$，$P(这个词词性|下一个词词性)*P(这个单词|这个词词性)$ 这些都不难统计和计算，但是对于未知的test，最难的问题就是当$C(这个词词性，下一个词词性)$或者$C(这个词词性，上一个词词性)$这样的组合从来没有出现，以及单词本身就不在train的词库里，自然$C(单词，词性)$这个组合也就出现不了，如果不做任何Smoothing处理，那么会导致对于一个生单词来讲，它所有的概率都将是0，这显然会导致一个句子bug的出现，所以smoothing处理是必然的。

对于词性来讲，通常的smoothing方式足以应对，但是对于未收录词语UNK，事情就变得稍微复杂了许多。

#### 个人解法：

##### 1. 最简单的add-one smoothing:

其实简单模仿一下HMM正向，就可以做一个双向的，比如说$P(这个词词性|下一个词词性)*P(这个单词|这个词词性)$

这样就可以用到前后两个方向的单词词性，作为判断一个单词的标准

然后跑两遍Viterbi算法，计算出对应一个句子它最佳的词性序列，一个正向，一个负向，对比，若两个序列对一个词标明的为同一词性则该词词性确定，若两个序列对一个词的标明有区别，取最大值，这样会导致更靠近句首的词更依赖前面，靠近句末的词更依赖后面。

一种效率非常低的方式首先想到，遍历test，提取其中所有的UNK，然后假设该UNK对于任意词性都出现过1次，这样简单的add-one，但是这样会导致比如说单词`Hahn`是NNP是8/93470，而对于FW出现次数仅有0/238，但是由于我分别多加了一次，就变成了9/93470对1/238，变成了按照概率显然后者要比前者出现的可能要大，这是不允许的，所以对于word使用**add-one smoothing**显然不好，于是放弃smoothing，改为直接预测，对于UNK，则使用看前面的单词词性直接计算最优后面接着的词性

还需要考虑log prob的问题

可以对单词的复数或者单数进行处理吗？

这个单纯的方法能得到：

0.9419520080616379



存在一些answer有错误的情况？我将我错误的答案进行了输出，发现了一些：

1. `House-Senate`在answer中只有NNP的形式，但是在train中有JJ的形式，然而理论上在test这个样例中，house-senate确实应该位JJ，所以这样的错误肯定不可避免。
2. `the/DT House/NNP Appropriations/NNP Committee/NNP`这个其中的Appropriations在train中就是NNP，但是在answer中却成了NNPS，说明answer也确有问题
3. 错的比较多的都是`JJ, VBG`, `VBZ, NNS`, `NN VBG`，`JJ, VBN`
4. 数字CD
5. 开头大写的字母且不在词库里的，尾巴又没有s的，非常有可能是NNP
6. insert竟然没有动词形式
7. 中间大写字母果然需要单独考虑



**question: Tri-gram是否可以做到呢**



暂且把目前的94.19%正确率叫做version0.5，接下来开始陆续更新



